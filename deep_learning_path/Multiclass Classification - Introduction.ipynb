{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcBI3k4/YQTxc/7+5FOpsM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Multiclass Classification Logic\n","\n","Multiclass classification aims to categorize a given input datum, denoted as \"x\", into one of several distinct categories. Specifically, this scenario is applicable when there are more than two possible classes, i.e., $K > 2$, thus the target variable $y$ belongs to a discrete set ${1, 2, ..., K}$.\n","\n","For the prediction space $y$, which is discrete and encompasses $K$ distinct categories, the selection of a probability distribution is crucial. Given the nature of $y$ as ${1, 2, ..., K}$, the categorical distribution is chosen. This distribution is characterized by $K$ parameters $\\lambda_1, \\lambda_2, ..., \\lambda_K$, each representing the probability of the corresponding category. The probability that $y$ equals a specific category $k$ is denoted as:\n","\n","$$Pr(y=k)=\\lambda_k$$\n","\n","The parameters $\\lambda_k$ of the categorical distribution must satisfy two conditions for the distribution to be valid: they should lie within the interval $[0, 1]$, and their sum must be exactly $1$. These constraints ensure that we are dealing with a proper probability distribution.\n","\n","The computation of the $K$ parameters from the input $x$ is performed using a network denoted as $f(x, \\phi)$, which outputs $K$ values. To enforce the aforementioned constraints on these outputs, they are passed through the softmax function. The softmax function transforms any real-valued vector of length $K$ into a probability distribution consisting of $K$ values in the range $[0, 1]$ that sum to $1$. The $k^{th}$ element of the softmax-transformed vector is calculated as follows, where the exponential function guarantees non-negative values:\n","\n","$$\\text{softmax}_k|z| = \\frac{exp|z_k|}{\\sum_{k'=1}^{K}exp|z_{k'}|}$$\n","\n","Given the setup, the likelihood that the input $x$ is assigned label $y$ equating to category $k$ is given by:\n","\n","$$Pr(y=k|x) = \\text{softmax}_k[f|x,\\phi|]$$\n","\n","The prediction $\\hat{y}$ is the category with the highest probability, determined as follows:\n","\n","$$\\hat{y} = \\text{argmax}_k[P r(y = k|f[x,\\hat{\\phi}])]$$\n","\n","The loss function, utilized for training the model, is defined as the negative log-likelihood of the observed labels in the training data set. This can be mathematically represented as:\n","\n","$$L|\\phi| = -\\sum_{i=1}^{I}log[\\text{softmax}_{y_i}|f|x_i,\\phi||]$$\n","\n","This formulation encapsulates the principle of maximizing the likelihood of the true labels given the model parameters, thereby facilitating the learning of an effective classification model."],"metadata":{"id":"MytfkTGU1tBr"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"lYZBwjLg1kKC","executionInfo":{"status":"ok","timestamp":1710318909519,"user_tz":-180,"elapsed":5,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","source":["**sample problem**:\n","\n","- Simulate logits for an input: [2.0, 1.0, 0.1] (these could be outputs from the last layer of a neural network before applying softmax).\n","- Apply the softmax function to convert logits into probabilities.\n","- Predict the class with the highest probability.\n","- Compute the loss using a true label (assume the true class is 1, represented as [1, 0, 0]).\n","\n","**Feature Representation**: We started with simplified feature vectors representing each fruit. In a real application, features would be extracted automatically by the neural network.\n","\n","**Simulated Neural Network Output (Logits)**: These logits are typically the output of the final layer of a neural network before applying the softmax function. They represent the network's raw predictions.\n","\n","**Softmax Function**: Converts raw logits into probabilities by applying the exponential function to each logit, normalizing them to ensure they sum to 1. This step is crucial because it allows us to interpret the network's output as probabilities.\n","\n","**Prediction**: We identify the class with the highest probability as our prediction. This step is straightforward but crucial for classification tasks."],"metadata":{"id":"XG0rZQWR_qIf"}},{"cell_type":"code","source":["def Softmax(values:np.ndarray)->np.ndarray:\n","  \"\"\"\n","  Compute softmax values for each sets of scores in values\n","  \"\"\"\n","  expValue = np.exp(values-np.max(values))\n","  return expValue/expValue.sum(axis=0)"],"metadata":{"id":"8ZLRpkYg81ix","executionInfo":{"status":"ok","timestamp":1710319040679,"user_tz":-180,"elapsed":395,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["values = np.array([2.0,1.0,0.1])"],"metadata":{"id":"Z3yTeH-q9XTJ","executionInfo":{"status":"ok","timestamp":1710319151698,"user_tz":-180,"elapsed":4,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Applying softmax to simulate neural network's output layer for class probabilities\n","probabilities = Softmax(values)\n","print(f\"Probabilities:\\n{probabilities}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oekJVLwD9yTt","executionInfo":{"status":"ok","timestamp":1710319182465,"user_tz":-180,"elapsed":7,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"82de642c-7e95-4287-95b7-a9604d662934"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilities:\n","[0.65900114 0.24243297 0.09856589]\n"]}]},{"cell_type":"code","source":["def PredictClass(probabilities:np.ndarray)->int|float:\n","  \"\"\"\n","  Predict the class with the highest probability\n","  \"\"\"\n","  return np.argmax(probabilities)+1 # Adding 1 to match the class labels 1, 2, ..., K"],"metadata":{"id":"XVYOieGq955H","executionInfo":{"status":"ok","timestamp":1710319268396,"user_tz":-180,"elapsed":14,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["predicted = PredictClass(probabilities)\n","print(f\"Predicted Class:\\n{predicted}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ggl2qejl-O9a","executionInfo":{"status":"ok","timestamp":1710319289049,"user_tz":-180,"elapsed":431,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"ab2d012a-4a1a-4aa1-bc78-81757e3678ab"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class:\n","1\n"]}]},{"cell_type":"code","source":["def CrossEntropyLoss(groundTruth:np.ndarray,probabilities:np.ndarray)->np.ndarray:\n","  return -np.sum(groundTruth*np.log(probabilities))"],"metadata":{"id":"id6fxD39-T2D","executionInfo":{"status":"ok","timestamp":1710319363453,"user_tz":-180,"elapsed":8,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Example true label for class 1 in one-hot encoding\n","groundTruth = np.array([1,0,0]) # Class 1"],"metadata":{"id":"QZnx9JzY-mJM","executionInfo":{"status":"ok","timestamp":1710319453398,"user_tz":-180,"elapsed":22,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["loss = CrossEntropyLoss(groundTruth,probabilities)\n","print(f\"Cross Entropy Loss:\\n{loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yP3HJZ9-8Hf","executionInfo":{"status":"ok","timestamp":1710319552147,"user_tz":-180,"elapsed":5,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"ecb14de5-5e19-44c6-881d-568300c3a736"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross Entropy Loss:\n","0.4170300162778335\n"]}]},{"cell_type":"markdown","source":["- **scenario**:\n","\n","Suppose we have a dataset of images, and each image is represented by a set of features extracted from the image. For simplicity, let's assume these features are already extracted and represent color intensity, texture, and size. Based on these features, we want to classify each image into one of the three categories (apple, banana, orange).\n","\n","For this example, let's assume we have the following feature vector for three images, representing an apple, a banana, and an orange, respectively:\n","\n","- Apple: [0.9, 0.1, 0.8] (High red intensity, low texture, medium size)\n","- Banana: [0.1, 0.3, 0.9] (Low red intensity, medium texture, large size)\n","- Orange: [0.8, 0.2, 0.7] (High red intensity, low texture, medium size)\n","\n","In a real scenario, a neural network trained on our dataset would produce a set of logits for each class based on the input features. For this example, let's simulate the logits for our three images:\n","\n","- Apple logits: [2.5, 0.5, 1.0]\n","- Banana logits: [1.0, 3.0, 0.5]\n","- Orange logits: [2.0, 1.0, 2.5]"],"metadata":{"id":"AgZX0OziAVwi"}},{"cell_type":"code","source":["appleLogit = np.array([2.5,0.5,1.0])\n","bananaLogit = np.array([1.0,3.0,0.5])\n","orangeLogit = np.array([2.0,1.0,2.5])"],"metadata":{"id":"Wuae1dR9_UJR","executionInfo":{"status":"ok","timestamp":1710320016322,"user_tz":-180,"elapsed":14,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["appleProbabilities = Softmax(appleLogit)\n","bananaProbabilities = Softmax(bananaLogit)\n","orangeProbabilities = Softmax(orangeLogit)\n","print(f\"Apple Probabilities: {appleProbabilities}\")\n","print(f\"Banana Probabilities: {bananaProbabilities}\")\n","print(f\"Orange Probabilities: {orangeProbabilities}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5m7MkQoBFYA","executionInfo":{"status":"ok","timestamp":1710320072107,"user_tz":-180,"elapsed":11,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"4446e98d-4495-4c8b-ac7a-317713a9954d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Apple Probabilities: [0.73612472 0.09962365 0.16425163]\n","Banana Probabilities: [0.11116562 0.82140902 0.06742536]\n","Orange Probabilities: [0.33149896 0.12195165 0.54654939]\n"]}]},{"cell_type":"code","source":["def PredictionClass(probabilities:np.ndarray)->int|float:\n","  classes = [\"Apple\",\"Banana\",\"Orange\"]\n","  return classes[np.argmax(probabilities)]"],"metadata":{"id":"o5HoYOf5BTHw","executionInfo":{"status":"ok","timestamp":1710320136779,"user_tz":-180,"elapsed":385,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["applePredicted = PredictionClass(appleProbabilities)\n","bananaPredicted = PredictionClass(bananaProbabilities)\n","orangePredicted = PredictionClass(orangeProbabilities)\n","print(f\"Predicted Class for Apple: {applePredicted}\")\n","print(f\"Predicted Class for Banana: {bananaPredicted}\")\n","print(f\"Predicted Class for Orange: {orangePredicted}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1VHmbJ2cBi0a","executionInfo":{"status":"ok","timestamp":1710320233183,"user_tz":-180,"elapsed":12,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"738865ce-9b43-4edb-8d61-210b5617fc7f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class for Apple: Apple\n","Predicted Class for Banana: Banana\n","Predicted Class for Orange: Orange\n"]}]},{"cell_type":"markdown","source":["- **scenario**:\n","\n","Imagine a customer service system designed to automatically categorize incoming text messages to streamline the response process. We'll simulate a simplified version of this task, focusing on the core aspects of preprocessing text data, vectorizing the text, and applying a classification model."],"metadata":{"id":"1JYG_sAnJy2S"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"q_LY16p7OeHR","executionInfo":{"status":"ok","timestamp":1710323611378,"user_tz":-180,"elapsed":5,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["data = [\n","    (\"What are your opening hours?\",\"Question\"),\n","    (\"Can you provide me with your location?\",\"Question\"),\n","    (\"Please cancel my subscription.\",\"Request\"),\n","    (\"I need information about my order.\",\"Request\"),\n","    (\"Tell me more about your products.\",\"Information\"),\n","    (\"How do I create an account?\",\"Question\"),\n","    (\"What types of payment do you accept?\",\"Question\"),\n","    (\"I'd like to know more about the refund policy.\",\"Information\"),\n","    (\"Please update my contact details.\",\"Request\"),\n","    (\"Can I change my delivery address?\",\"Request\")\n","]"],"metadata":{"id":"oMJh-aJ1B6gb","executionInfo":{"status":"ok","timestamp":1710323509062,"user_tz":-180,"elapsed":316,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["messages,labels = zip(*data)"],"metadata":{"id":"KvNCt3qsKG3i","executionInfo":{"status":"ok","timestamp":1710323644199,"user_tz":-180,"elapsed":34,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["vectorizer = TfidfVectorizer(stop_words=\"english\",max_features=100)"],"metadata":{"id":"Fd2PmznvO7S8","executionInfo":{"status":"ok","timestamp":1710323669777,"user_tz":-180,"elapsed":11,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["xData = vectorizer.fit_transform(messages)"],"metadata":{"id":"VLEEdv11PBhP","executionInfo":{"status":"ok","timestamp":1710323687088,"user_tz":-180,"elapsed":315,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(f\"Shape of data: {xData.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQQoOq6FPFp3","executionInfo":{"status":"ok","timestamp":1710323703287,"user_tz":-180,"elapsed":18,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"080b8a14-bdd4-42cf-f327-acc083b87877"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of data: (10, 26)\n"]}]},{"cell_type":"code","source":["labelEngine = LabelEncoder()"],"metadata":{"id":"ySaDkHZZPGI6","executionInfo":{"status":"ok","timestamp":1710323716717,"user_tz":-180,"elapsed":17,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["yValues = labelEngine.fit_transform(labels)"],"metadata":{"id":"Ld-63hfCPM8i","executionInfo":{"status":"ok","timestamp":1710323735836,"user_tz":-180,"elapsed":8,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["print(f\"Shape of labels: {yValues.shape}\")\n","print(f\"Labels:\\n{set(yValues)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yN0IgjENPRq2","executionInfo":{"status":"ok","timestamp":1710323768187,"user_tz":-180,"elapsed":6,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"9f03bb03-6a5a-403d-8663-67c7088f0026"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of labels: (10,)\n","Labels:\n","{0, 1, 2}\n"]}]},{"cell_type":"code","source":["xTrain,xTest,yTrain,yTest = train_test_split(xData,yValues,test_size=0.2,random_state=45)"],"metadata":{"id":"t1EuOKzhPSu3","executionInfo":{"status":"ok","timestamp":1710323798228,"user_tz":-180,"elapsed":284,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model = LogisticRegression()"],"metadata":{"id":"A1wjXpeaPg1D","executionInfo":{"status":"ok","timestamp":1710323806322,"user_tz":-180,"elapsed":3,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["model.fit(xTrain,yTrain)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"1KD1fDfXPi2b","executionInfo":{"status":"ok","timestamp":1710323817352,"user_tz":-180,"elapsed":304,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"f62b0993-eac2-4473-c155-3ff08fa8aa0b"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["- just for example"],"metadata":{"id":"qhc8o_AvQnC4"}},{"cell_type":"code","source":["predictions = model.predict(xTest)"],"metadata":{"id":"261FwVfHPldy","executionInfo":{"status":"ok","timestamp":1710323826033,"user_tz":-180,"elapsed":8,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["accuracyManuel = sum(1 for true,predicted in zip(yTest,predictions) if true == predicted)/len(yValues)*100\n","print(f\"Accuracy-Manuel: % {int(accuracyManuel)}\")\n","accuracy = accuracy_score(predictions,yTest)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVXSazg3Pnox","executionInfo":{"status":"ok","timestamp":1710324072119,"user_tz":-180,"elapsed":303,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"22d1fc1b-1888-4415-b927-8cff74119814"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy-Manuel: % 0\n","Accuracy: 0.0\n"]}]},{"cell_type":"code","source":["def ClassifyMessage(model,vectorizer,labelEncoder,message)->str:\n","  vectorized = vectorizer.transform([message])\n","  prediction = model.predict(vectorized)\n","  labels = labelEncoder.inverse_transform(prediction)[0]\n","  return labels"],"metadata":{"id":"zrFs6I_UPwK3","executionInfo":{"status":"ok","timestamp":1710324169706,"user_tz":-180,"elapsed":7,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["message = \"How can I track my shipment?\"\n","prediction = ClassifyMessage(model,vectorizer,labelEngine,message)\n","print(f\"Prediction: {prediction} for --> {message}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AC0aghldQ7LQ","executionInfo":{"status":"ok","timestamp":1710324217776,"user_tz":-180,"elapsed":315,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"57ca19c7-e065-437d-84de-248cc654c44f"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: Question for --> How can I track my shipment?\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yfNu5Yh0RE-d"},"execution_count":null,"outputs":[]}]}