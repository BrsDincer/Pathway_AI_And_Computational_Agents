{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7g5/T9vmuF8yzQm+2tOu6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Binary Classification Logic\n","\n","In the domain of binary classification, the primary objective is to categorize the provided data, denoted by \"x\", into one of two distinct classes, symbolized as $y \\in {0, 1}$. Within this framework, \"y\" is referred to as a \"label\".\n","\n","Initially, the process involves selecting a probability distribution that spans the output space $y \\in {0, 1}$. A commonly utilized distribution for this purpose is the Bernoulli distribution. This distribution is characterized by its definition on the discrete set ${0, 1}$ and is parameterized by a single parameter $\\lambda \\in (0, 1)$, which signifies the probability of the event where “$y$” assumes the value of one. The probability mass function of the Bernoulli distribution can be articulated as:\n","\n","$$\\begin{equation}\n","Pr(y|\\lambda) = (1-\\lambda)^{1-y} \\cdot \\lambda^y\n","\\end{equation}$$\n","\n","Alternatively, this can be expressed through piecewise function notation as:\n","\n","$$\\begin{equation}\n","Pr(y|\\lambda) =\n","\\begin{cases}\n","1-\\lambda & \\text{if } y=0 \\\\\n","\\lambda & \\text{if } y=1 \\\\\n","\\end{cases}\n","\\end{equation}$$\n","\n","Subsequently, the objective is to configure a machine learning model, denoted by $f(x, \\phi)$, to predict the single distribution parameter “$\\lambda$”. Given that “$\\lambda$” must only occupy values within the interval [0, 1], and the output of the network may not inherently conform to this constraint, the output is then transformed through a mapping function that converts real numbers $\\mathbb{R}$ to the interval [0, 1]. An appropriate function for this conversion is the “logistic sigmoid”, represented as:\n","\n","$$\\begin{equation}\n","sig(z) = \\frac{1}{1+\\exp(-z)}\n","\\end{equation}$$\n","\n","Therefore, the prediction of the distribution parameter $\\lambda$ is computed as $\\lambda = sig(f(x,\\phi))$:\n","\n","$$\\begin{equation}\n","Pr(y|x) = (1 - sig(f(x,\\phi)))^{1-y} \\cdot sig(f(x,\\phi))^y\n","\\end{equation}$$\n","\n","The loss function, essential for training the model, is designated as the negative log-likelihood of the observed training set. This function is pivotal for optimizing the parameters $\\phi$ of the model and is mathematically defined as:\n","\n","$$\\begin{equation}\n","L(\\phi) = \\sum_{i=1}^{I} -[(1-y_i) \\cdot \\log(1-sig(f(x_i,\\phi))) + y_i \\cdot \\log(sig(f(x_i,\\phi)))]\n","\\end{equation}$$\n","\n","During the inference phase, a point estimate of \"y\" is often required. To determine this, a threshold is set such that \"y\" is assigned a value of 1 if $\\lambda > 0.5$, and a value of 0 otherwise, enabling the model to make binary decisions based on the predicted probabilities."],"metadata":{"id":"yOIewSrJnFcT"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"9WT7lqnEmw9P","executionInfo":{"status":"ok","timestamp":1710269189334,"user_tz":-180,"elapsed":1559,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"outputs":[],"source":["import numpy as np\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","source":["def BernoulliProbability(label:int,lambdaValue:int|float)->int|float:\n","  \"\"\"\n","    Calculates the probability of y given lambda using the Bernoulli distribution.\n","\n","    Parameters:\n","    - label: The binary class label (0 or 1).\n","    - lambdaValue: The probability of y being 1.\n","\n","    Returns:\n","    - Probability of label given lambda.\n","  \"\"\"\n","  return (1-lambdaValue)**(1-label)*lambdaValue**label"],"metadata":{"id":"-GBFOfoCihpY","executionInfo":{"status":"ok","timestamp":1710269189334,"user_tz":-180,"elapsed":20,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def LogisticSigmoid(value:np.ndarray)->np.ndarray:\n","  return 1/(1+np.exp(-value))"],"metadata":{"id":"aC6LClyCi4g2","executionInfo":{"status":"ok","timestamp":1710269189334,"user_tz":-180,"elapsed":19,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def LinearModel(sample:np.ndarray,phi:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    A simplistic linear model for demonstration. In practice, this would be replaced\n","    with a more complex model, like a neural network.\n","\n","    Parameters:\n","    - sample: Input features.\n","    - phi: Model parameters.\n","\n","    Returns:\n","    - Predicted value before applying sigmoid.\n","  \"\"\"\n","  return np.dot(sample,phi)"],"metadata":{"id":"vnXnCKldjICh","executionInfo":{"status":"ok","timestamp":1710269189335,"user_tz":-180,"elapsed":20,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def PredictLambda(sample:np.ndarray,phi:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    Predicts lambda by applying the sigmoid function on the model's output.\n","\n","    Parameters:\n","    - sample: Input features.\n","    - phi: Model parameters.\n","\n","    Returns:\n","    - Predicted lambda.\n","  \"\"\"\n","  value = LinearModel(sample,phi)\n","  return LogisticSigmoid(value)"],"metadata":{"id":"jvfXVKixjskZ","executionInfo":{"status":"ok","timestamp":1710269189335,"user_tz":-180,"elapsed":19,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def BinaryClassificationLoss(labels:np.ndarray,sample:np.ndarray,phi:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    Computes the negative log-likelihood loss for binary classification.\n","\n","    Parameters:\n","    - labels: Array of binary class labels.\n","    - sample: Input features.\n","    - phi: Model parameters.\n","\n","    Returns:\n","    - The negative log-likelihood loss.\n","  \"\"\"\n","  lambdaPrediction = PredictLambda(sample,phi)\n","  loss = -(np.sum((1-labels)*np.log(1-lambdaPrediction)+labels*np.log(lambdaPrediction)))\n","  return loss"],"metadata":{"id":"mDDF0Ll3j43z","executionInfo":{"status":"ok","timestamp":1710269189335,"user_tz":-180,"elapsed":18,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def MakePrediction(sample:np.ndarray,phi:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    Makes a binary prediction based on the predicted lambda.\n","\n","    Parameters:\n","    - sample: Input features.\n","    - phi: Model parameters.\n","\n","    Returns:\n","    - Binary class prediction (0 or 1).\n","  \"\"\"\n","  lambdaPrediction = PredictLambda(sample,phi)\n","  return (lambdaPrediction>0.5).astype(int)"],"metadata":{"id":"d6kj0XPZkQpC","executionInfo":{"status":"ok","timestamp":1710269189335,"user_tz":-180,"elapsed":18,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["irisData = datasets.load_iris()\n","sample = irisData.data[:,2:]  # We only use petal length and petal width for simplicity\n","groundTruth = (irisData.target==0).astype(int) # 1 if Setosa, 0 otherwise"],"metadata":{"id":"7LLGATyukoE7","executionInfo":{"status":"ok","timestamp":1710269189335,"user_tz":-180,"elapsed":17,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(f\"Labels:\\n{set(groundTruth)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdEWKIklk5CD","executionInfo":{"status":"ok","timestamp":1710269189335,"user_tz":-180,"elapsed":17,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"25d5eeb8-95a6-4478-d729-f9dc4d799f31"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels:\n","{0, 1}\n"]}]},{"cell_type":"code","source":["print(f\"Data shape:\\n{sample.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDHOrsTKk7fH","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":15,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"5b9f1549-d184-4fd6-93b8-e9881487e65f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Data shape:\n","(150, 2)\n"]}]},{"cell_type":"code","source":["# Split dataset into training and testing sets\n","xTrain,xTest,yTrain,yTest = train_test_split(sample,groundTruth,test_size=0.2,random_state=45)"],"metadata":{"id":"fCxVya0qk-1x","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":13,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def UpdatePhiValues(sample:np.ndarray,groundTruth:np.ndarray,phi:np.ndarray,learningRate=0.01)->np.ndarray:\n","  \"\"\"\n","    Updates the model parameters using gradient descent.\n","\n","    Parameters:\n","    - sample: Input features.\n","    - groundTruth: True labels.\n","    - phi: Current model parameters.\n","    - learningRate: Step size for gradient descent.\n","\n","    Returns:\n","    - Updated model parameters.\n","  \"\"\"\n","  count = len(groundTruth)\n","  lambdaPrediction = PredictLambda(sample,phi)\n","  gradient = np.dot(sample.T,(lambdaPrediction-groundTruth))/count\n","  phiUpdated = phi-learningRate*gradient\n","  return phiUpdated"],"metadata":{"id":"I_G1I2dQlG3U","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":13,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["phiValues = np.random.randn(2) # random initialize parameters"],"metadata":{"id":"RuyJE5celvd-","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":13,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(f\"Phi Values:\\n{phiValues}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhYo0nx9l7BC","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":12,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"6d26680b-0b19-4794-e792-27c4f122862d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Phi Values:\n","[-0.78721354 -0.5843397 ]\n"]}]},{"cell_type":"code","source":["for epoch in range(1000):\n","  phi = UpdatePhiValues(xTrain,yTrain,phiValues)"],"metadata":{"id":"aDNm3F2Bl9Hk","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":11,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["predictions = MakePrediction(xTest,phi)\n","print(f\"Prediction Labels:\\n{set(predictions)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUXQ4SpRmM6N","executionInfo":{"status":"ok","timestamp":1710269189336,"user_tz":-180,"elapsed":10,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"a6a6d83f-eb99-4a17-e9e6-0ce2b491955d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction Labels:\n","{0}\n"]}]},{"cell_type":"code","source":["accuracy = accuracy_score(yTest,predictions)\n","print(f\"Model Accuracy:\\n{accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9HYvUBfm5mV","executionInfo":{"status":"ok","timestamp":1710269189337,"user_tz":-180,"elapsed":10,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"f6dc3910-61c3-40f3-d50e-6d585e644f62"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy:\n","0.6333333333333333\n"]}]},{"cell_type":"markdown","source":["- another example:"],"metadata":{"id":"NwmnYq_pvuHK"}},{"cell_type":"code","source":["def BernoulliProbability(labels:np.ndarray,lambdaParameters:np.ndarray)->int|float:\n","  \"\"\"\n","    Bernoulli probability mass function.\n","\n","    Parameters:\n","    - labels: The binary outcome (0 or 1).\n","    - lambdaParameters: The probability of the outcome being 1.\n","\n","    Returns:\n","    - The probability of labels given lambda.\n","  \"\"\"\n","  return (1-lambdaParameters)**(1-labels)*lambdaParameters**labels"],"metadata":{"id":"JHfN5cDcm_zK","executionInfo":{"status":"ok","timestamp":1710269828495,"user_tz":-180,"elapsed":5,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def LogisticSigmoid(value:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    Logistic sigmoid function, mapping any real number to the (0, 1) interval.\n","\n","    Parameters:\n","    - value: The input value(s).\n","\n","    Returns:\n","    - The sigmoid of value.\n","  \"\"\"\n","  return 1/(1+np.exp(-value))"],"metadata":{"id":"rLDXWDme_LaQ","executionInfo":{"status":"ok","timestamp":1710269828872,"user_tz":-180,"elapsed":4,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def ModelPrediction(sample:np.ndarray,phiValues:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    Predicts the probability of y=1 using the logistic sigmoid on the linear model output.\n","\n","    Parameters:\n","    - sample: The input features.\n","    - phiValues: The model parameters.\n","\n","    Returns:\n","    - The predicted probability of y being 1.\n","  \"\"\"\n","  value = np.dot(sample,phiValues)\n","  return LogisticSigmoid(value)"],"metadata":{"id":"Rw1r-LBm_byT","executionInfo":{"status":"ok","timestamp":1710269828872,"user_tz":-180,"elapsed":3,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def ComputeLoss(groundTruth:np.ndarray,sample:np.ndarray,phiValues:np.ndarray)->np.ndarray:\n","  \"\"\"\n","    Computes the negative log-likelihood loss for binary classification.\n","\n","    Parameters:\n","    - groundTruth: The true labels.\n","    - sample: The input features.\n","    - phiValues: The model parameters.\n","\n","    Returns:\n","    - The computed loss.\n","  \"\"\"\n","  predictions = ModelPrediction(sample,phiValues)\n","  loss = -np.mean(groundTruth*np.log(predictions)+(1-groundTruth)*np.log(1-predictions))\n","  return loss"],"metadata":{"id":"qYisDmw__tBl","executionInfo":{"status":"ok","timestamp":1710269828873,"user_tz":-180,"elapsed":4,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def UpdateParameters(sample:np.ndarray,groundTruth:np.ndarray,phiValues:np.ndarray,learningRate:float=0.01)->np.ndarray:\n","  \"\"\"\n","    Updates the model parameters using gradient descent.\n","\n","    Parameters:\n","    - sample: The input features.\n","    - groundTruth: The true labels.\n","    - phiValues: The model parameters.\n","    - learningRate: The learning rate for gradient descent.\n","\n","    Returns:\n","    - Updated model parameters.\n","  \"\"\"\n","  predictions = ModelPrediction(sample,phiValues)\n","  gradient = np.dot(sample.T,(predictions-groundTruth))/len(groundTruth)\n","  phiUpdated = phiValues-learningRate*gradient\n","  return phiUpdated"],"metadata":{"id":"b5KOFGATAH5r","executionInfo":{"status":"ok","timestamp":1710269829234,"user_tz":-180,"elapsed":4,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def BinaryClassificationInference(sample:np.ndarray,phiValues:np.ndarray)->np.ndarray:\n","  probabilities = ModelPrediction(sample,phiValues)\n","  return (probabilities>0.5).astype(int)"],"metadata":{"id":"aeyrcowWAe3A","executionInfo":{"status":"ok","timestamp":1710269829235,"user_tz":-180,"elapsed":4,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["sample = np.array([[5,2],[3,5],[6,1.5],[2,3]]) # Feature matrix\n","groundTruth = np.array([1,0,1,0]) # True labels"],"metadata":{"id":"58LRHZCGAvDj","executionInfo":{"status":"ok","timestamp":1710269829645,"user_tz":-180,"elapsed":9,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["phiValues = np.random.rand(sample.shape[1])\n","print(f\"Phi Values:\\n{phiValues}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj4Bfqv5A5Iv","executionInfo":{"status":"ok","timestamp":1710269829646,"user_tz":-180,"elapsed":8,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"dee0ef24-4aa5-405d-cb93-669b3ebfd94b"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Phi Values:\n","[0.13385617 0.22222434]\n"]}]},{"cell_type":"code","source":["iterations = 1000\n","learningRate = 0.01\n","for idx in range(iterations):\n","  phiValues = UpdateParameters(sample,groundTruth,phiValues,learningRate)\n","  if idx % 100 == 0:\n","    print(f\"Loss at iteration: {idx} --> ::[{ComputeLoss(groundTruth,sample,phiValues)}]::\")\n","predictions = BinaryClassificationInference(sample,phiValues)\n","print(f\"Predictions:\\n{predictions}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sYRjr_nBDr7","executionInfo":{"status":"ok","timestamp":1710269830032,"user_tz":-180,"elapsed":6,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}},"outputId":"21ff9118-0273-404c-85fa-a5fdd4f1d676"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss at iteration: 0 --> ::[0.8661142104923024]::\n","Loss at iteration: 100 --> ::[0.3142663868497561]::\n","Loss at iteration: 200 --> ::[0.18990551803602562]::\n","Loss at iteration: 300 --> ::[0.13646302662037677]::\n","Loss at iteration: 400 --> ::[0.10694560435903737]::\n","Loss at iteration: 500 --> ::[0.08820184442972846]::\n","Loss at iteration: 600 --> ::[0.07521487839898558]::\n","Loss at iteration: 700 --> ::[0.06566656108823572]::\n","Loss at iteration: 800 --> ::[0.05833884639559832]::\n","Loss at iteration: 900 --> ::[0.05253011549673224]::\n","Predictions:\n","[1 0 1 0]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tngpRJI7BhiC","executionInfo":{"status":"ok","timestamp":1710269830372,"user_tz":-180,"elapsed":4,"user":{"displayName":"Baris Dincer","userId":"16400678175301643843"}}},"execution_count":39,"outputs":[]}]}